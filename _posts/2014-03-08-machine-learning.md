---
layout: math
title: Machine Learning
lang: ru
description: Очень краткие конспекты лекций по ML с Coursera
---

Записался на курс [Machine Learning][1] на Coursera. Попробую целиком
прослушать и сдать экзамен. Пока прослушал первую неделю, там было только
вступление. На удивление, могу спокойно слушать и понимать английский язык
преподавателя.

Здесь буду записывать очень краткие конспекты лекций.

## Week 1

Определение ML:

> A computer program is said to learn from experience E, with respect to some
> task T, and some performance measure P, if its performance on T as measured
> by P improves with experience E.
>
> _Tom Mitchell_

Задачи, решаемые ML:

* Data mining во всех его проявлениях -- обработка медицинских данных, данных
  соцсетей, предпочтения в интернет-магазинах, контекстная реклама
* Приложения, которые невозможно написать -- автономный вертолет, распознование
  символов, Natural Language Processing, компьютерное зрение.

Два типа ML:

* Supervised learning
* Unsupervised learning

### Supervised Learning

Supervised Learning -- это когда у нас есть набор данных E, по которым
_известен_ результат решения задачи T. Стоит задача для _новых_ данных получить
результат.

Примеры:

* Регрессия -- есть факты по стоимости квадратного метра жилья в зависимости от
  площади. Требуется для нового значения площади определить стоимость.
* Спам-фильтр -- обучаем машину вручную отмечая спам-письма, дальше она сама
  учится помечать спам
* Медицинские данные (например, по факту злокачественной раковой опухоли груди)
  -- знаем, факты, когда для определенного объема опухоли и возраста пациента
  опухоль была злокачественной или нет, задача - для нового пациента определить
  тип опухоли

Первый пример -- Regression Problem, два последних примера -- пример
Classification Problem. В Classification Problem стоит задача по _в принципе
бесконечному_ количеству результатов проклассифицировать данные по какому-то
принципу.

### Unsupervised Learning

Unsupervised Learning -- принцип тот же, что и в Supervised Learning, только
результата "правильных" значений нет. Пример задач -- разбиение данных на
группы, выделение фрагментов.

Человек визуально эту задачу решает очень хорошо -- мозг настроен на выделение
паттернов. Задача -- научить этому машину.

Примеры:

* Сегментация клиентов бизнеса по группам
* Анализ данных соц. сетей
* Группировка разных новостей из разных источников в топики -- Google News
* Геном человека -- нужно выделить группы генов, которые есть у разных типов
  людей
* Астрономические данные -- выделение туманностей и галактик
* Разделение дорожек в аудио данных


### Training Set

В случае Supervised Learning исходный набор данных с решенной задачей
называется Training Set. В самом простом случае регрессии это двумерный набор
данных \\((x, y)\\).

Training Set подается в Learning Algorithm и на выходе получается гипотеза
(Hypothesis) h. Эта "гипотеза" и есть обученный алгоритм, что если мы на вход
подадим какое-то новое \\(x'\\), отсутствующее в Training Set, то получим
результат работы нашей модели.

    h :: x -> y
    map h [x] = [y]

## Week 2

### Регрессия

Самый простой случай решения задачи регрессии -- линейная регрессия. В этом
случае функцией \\(h\\) является прямая.

<div>
{% raw %}
\[ h(x) = \theta_{0} + \theta_{1} x \]
{% endraw %}
</div>

В этом случае, задача сводится к поиску оптимальных коэффициентов прямой.

Задача имеет \\(n\\) features (параметров, но это слово уже занято для
\\(\theta_j\\) и \\(m\\) наборов данных в тренировочном наборе.

Конструируют некоторую функцию веса ошибки \\(J(\Theta)\\) от вектора
параметров размерностью \\(n+1\\):

<div>
{% raw %}
\[\Theta = [\theta_0, \theta_1, ..., \theta_n] \]
{% endraw %}
</div>

Обычно это среднеквадратичное отклонение:

<div>
{% raw %}
\[ J(\Theta) = \frac{1}{2m} \sum_{i=0}^m \left(h_{\theta}(x^{(i)}) - y^{(i)}\right)^2 \]
{% endraw %}
</div>

Т.к. параметров, определяющих алгоритм может быть множество (в качестве примера
-- зависимость стоимости дома от площади, этажа, года постройки, количества
спален), удобно пользоваться аппаратом линейной алгебры -- исходные наборы
представляются в виде матрицы \\(X\\), а параметры регрессии -- в виде вектора
\\(\Theta\\). Тогда, положив \\(x_0 = 1\\), конкретное значение получается в
виде:

<div>
{% raw %}
\[ h_\theta(x) = \Theta^T x \]
{% endraw %}
</div>


Задачей является поиск таких параметров \\(\Theta\\), для которых вес ошибки
будет минимальным.

Минимум функции веса ошибки \\(J(\Theta)\\) ищут с помощью градиентного спуска
или с помощью явного аналитического решения с помощью линейной алгебры.

### Градиентный спуск (Gradient descent)

Выбираем некое начальное значение параметров. Одновременно вычисляем новые
значения для всех \\(\theta_j\\):

<div>
{% raw %}
\[ \theta_j = \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\Theta) \]
{% endraw %}
</div>

до тех пор, пока изменение \\(J(\Theta)\\) не упадет до малого значения (обычно
- 0.001).

Здесь \\(\alpha\\) -- параметр скорости обучения. Если его взять слишком
большим, то спуск пропустит локальный минимум и функция веса ошибки будет
расходящейся. Если его взять слишком маленьким, то спуск будет очень медленным.
Оптимально начинать с некотого начального значения, например, 0.01, и строить
зависимость функции ошибки от количества итерация. Дальше подбирать параметры
исходя от вида графика этой функции. Расходится -- уменьшаем (удобно -- в 3
раза), сходится медленно -- увеличиваем.

Чтобы была скорость работы градиентного спуска была оптимальной также
рекомендуется провести нормализацию и усреднение значений features, чтобы все
они находились в интервале \\(-1 <= x <= 1\\).

В случае линейной регрессии можно аналитически вычислить частные производные
функции ошибки по параметру и использовать результат в явном виде, чтобы не
производить численный расчет производной.

<div>
{% raw %}
\[ \theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=0}^{m} \left ( h_\theta (x^{(i)}) - y^{(i)} \right ) x_j^{(i)} \]
{% endraw %}
</div>

### Решение в аналитическом виде

Глобальный минимум для функции ошибки \\(J(\Theta)\\) -- точка, в которой все
частичные производные по компонентам \\(\Theta\\) равны нулю. Исходя из этого,
можно аналитически вычислить оптимальное значение \\(\Theta\\). Для случая
линейной регрессии получается следующая формула:

<div>
{% raw %}
\[ \Theta = (X^T X)^{-1}X^Ty \]
{% endraw %}
</div>

Здесь \\(X\\) -- матрица размера \\(m \times n+1 \\) с исходными данными из
обучающего набора, \\(y\\) -- вектор с результатами обучающего набора.

Сложность расчета здесь в вычислении компонента \\((X^T X)^{-1}\\). Также может
оказаться, что для этой матрицы нет обратной. Такое обычно случается если среди
features есть линейно зависимые друг от друга (например, площадь дома в
квадратных футах и площать дома в квадратных метрах). В этом случае надо
исключить одну из таких features.

В случае решения в аналитическом виде нет необходимости проводить нормализацию и
усреднение данных из обучающего набора.

С современными мощностями можно использовать решение в аналитическом виде вплоть
до 10000 features и строк в обучающем наборе. При большем количестве имеет смысл
использовать градиентный спуск.


[1]: https://www.coursera.org/course/ml
