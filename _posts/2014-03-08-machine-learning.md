---
layout: math
title: Machine Learning
lang: ru
description: Очень краткие конспекты лекций по ML с Coursera
---

Записался на курс [Machine Learning][1] на Coursera. Попробую целиком
прослушать и сдать экзамен.

Здесь буду записывать очень краткие конспекты лекций.

## Week 1

Определение ML:

> A computer program is said to learn from experience E, with respect to some
> task T, and some performance measure P, if its performance on T as measured
> by P improves with experience E.
>
> _Tom Mitchell_

Задачи, решаемые ML:

* Data mining во всех его проявлениях -- обработка медицинских данных, данных
  соцсетей, предпочтения в интернет-магазинах, контекстная реклама
* Приложения, которые невозможно написать -- автономный вертолет, распознование
  символов, Natural Language Processing, компьютерное зрение.

Два типа ML:

* Supervised learning
* Unsupervised learning

### Supervised Learning

Supervised Learning -- это когда у нас есть набор данных E, по которым
_известен_ результат решения задачи T. Стоит задача для _новых_ данных получить
результат.

Примеры:

* Регрессия -- есть факты по стоимости квадратного метра жилья в зависимости от
  площади. Требуется для нового значения площади определить стоимость.
* Спам-фильтр -- обучаем машину вручную отмечая спам-письма, дальше она сама
  учится помечать спам
* Медицинские данные (например, по факту злокачественной раковой опухоли груди)
  -- знаем, факты, когда для определенного объема опухоли и возраста пациента
  опухоль была злокачественной или нет, задача - для нового пациента определить
  тип опухоли

Первый пример -- Regression Problem, два последних примера -- пример
Classification Problem. В Classification Problem стоит задача по _в принципе
бесконечному_ количеству результатов проклассифицировать данные по какому-то
принципу.

### Unsupervised Learning

Unsupervised Learning -- принцип тот же, что и в Supervised Learning, только
результата "правильных" значений нет. Пример задач -- разбиение данных на
группы, выделение фрагментов.

Человек визуально эту задачу решает очень хорошо -- мозг настроен на выделение
паттернов. Задача -- научить этому машину.

Примеры:

* Сегментация клиентов бизнеса по группам
* Анализ данных соц. сетей
* Группировка разных новостей из разных источников в топики -- Google News
* Геном человека -- нужно выделить группы генов, которые есть у разных типов
  людей
* Астрономические данные -- выделение туманностей и галактик
* Разделение дорожек в аудио данных


### Training Set

В случае Supervised Learning исходный набор данных с решенной задачей
называется Training Set. В самом простом случае регрессии это двумерный набор
данных \\((x, y)\\).

Training Set подается в Learning Algorithm и на выходе получается гипотеза
(Hypothesis) h. Эта "гипотеза" и есть обученный алгоритм, что если мы на вход
подадим какое-то новое \\(x'\\), отсутствующее в Training Set, то получим
результат работы нашей модели.

    h :: x -> y
    map h [x] = [y]

## Week 2

### Регрессия

Самый простой случай решения задачи регрессии -- линейная регрессия. В этом
случае функцией \\(h\\) является прямая.

<div>
{% raw %}
\[ h(x) = \theta_{0} + \theta_{1} x \]
{% endraw %}
</div>

В этом случае, задача сводится к поиску оптимальных коэффициентов прямой.

Задача имеет \\(n\\) features (параметров, но это слово уже занято для
\\(\theta_j\\)) и \\(m\\) наборов данных в тренировочном наборе.

Конструируют некоторую функцию веса ошибки \\(J(\Theta)\\) от вектора
параметров размерностью \\(n+1\\):

<div>
{% raw %}
\[\Theta = [\theta_0, \theta_1, ..., \theta_n] \]
{% endraw %}
</div>

Обычно это среднеквадратичное отклонение:

<div>
{% raw %}
\[ J(\Theta) = \frac{1}{2m} \sum_{i=0}^m \left(h_{\theta}(x^{(i)}) - y^{(i)}\right)^2 \]
{% endraw %}
</div>

Т.к. параметров, определяющих алгоритм может быть множество (в качестве примера
-- зависимость стоимости дома от площади, этажа, года постройки, количества
спален), удобно пользоваться аппаратом линейной алгебры -- исходные наборы
представляются в виде матрицы \\(X\\), а параметры регрессии -- в виде вектора
\\(\Theta\\). Тогда, положив \\(x_0 = 1\\), конкретное значение получается в
виде:

<div>
{% raw %}
\[ h_\theta(x) = \Theta^T x \]
{% endraw %}
</div>


Задачей является поиск таких параметров \\(\Theta\\), для которых вес ошибки
будет минимальным.

Минимум функции веса ошибки \\(J(\Theta)\\) ищут с помощью градиентного спуска
или с помощью явного аналитического решения с помощью линейной алгебры.

### Градиентный спуск (Gradient descent)

Выбираем некое начальное значение параметров. Одновременно вычисляем новые
значения для всех \\(\theta_j\\):

<div>
{% raw %}
\[ \theta_j = \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\Theta) \]
{% endraw %}
</div>

до тех пор, пока изменение \\(J(\Theta)\\) не упадет до малого значения (обычно
-- 0.001).

Здесь \\(\alpha\\) -- параметр скорости обучения. Если его взять слишком
большим, то спуск пропустит локальный минимум и функция веса ошибки будет
расходящейся. Если его взять слишком маленьким, то спуск будет очень медленным.
Оптимально начинать с некотого начального значения, например, 0.01, и строить
зависимость функции ошибки от количества итерация. Дальше подбирать параметры
исходя от вида графика этой функции. Расходится -- уменьшаем (удобно -- в 3
раза), сходится медленно -- увеличиваем.

Чтобы была скорость работы градиентного спуска была оптимальной,
рекомендуется провести нормализацию и усреднение значений features, чтобы все
они находились в интервале \\(-1 <= x <= 1\\). Для нормализации значений
используется формула:

<div>
{% raw %}
\[ x_j^{(i)} = \frac{x_j^{(i)} - \mu^{(i)}}{ \sigma^{(i)} } \]
{% endraw %}
</div>

Здесь \\(\mu^{(i)}\\) -- среднее по всем \\(x^{(i)}\\), \\(\sigma^{(i)}\\) --
стандартное отклонение по всем \\(x^{(i)}\\). В дальнейшем, при задании
расчетных значений их также необходимо нормализовывать по такой же формуле. При
этом результирующие значения \\( y \\) не надо нормализовать.

В случае линейной регрессии можно аналитически вычислить частные производные
функции ошибки по параметру и использовать результат в явном виде, чтобы не
производить численный расчет производной.

<div>
{% raw %}
\[ \theta_j = \theta_j - \alpha \frac{1}{m} \sum_{i=0}^{m} \left ( h_\theta (x^{(i)}) - y^{(i)} \right ) x_j^{(i)} \]
{% endraw %}
</div>

### Решение в аналитическом виде

Глобальный минимум для функции ошибки \\(J(\Theta)\\) -- точка, в которой все
частичные производные по компонентам \\(\Theta\\) равны нулю. Исходя из этого,
можно аналитически вычислить оптимальное значение \\(\Theta\\). Для случая
линейной регрессии получается следующая формула:

<div>
{% raw %}
\[ \Theta = (X^T X)^{-1}X^Ty \]
{% endraw %}
</div>

Здесь \\(X\\) -- матрица размера \\(m \times n+1 \\) с исходными данными из
обучающего набора, \\(y\\) -- вектор с результатами обучающего набора.

Сложность расчета здесь в вычислении компонента \\((X^T X)^{-1}\\). Также может
оказаться, что для этой матрицы нет обратной. Такое обычно случается если среди
features есть линейно зависимые друг от друга (например, площадь дома в
квадратных футах и площать дома в квадратных метрах). В этом случае надо
исключить одну из таких features.

В случае решения в аналитическом виде нет необходимости проводить нормализацию и
усреднение данных из обучающего набора.

С современными мощностями можно использовать решение в аналитическом виде вплоть
до 10000 features и строк в обучающем наборе. При большем количестве имеет смысл
использовать градиентный спуск. При этом количество строк в обучающем наборе
оказывается неважным -- перемножение \\(X^T X\\) это перемножение матриц
размерностей \\( n \times m \\) и \\( m \times n \\), так что в результате
получается матрица размера \\( n \times n \\), для которой необходимо вычислить
обратную матрицу.


### Эксперименты с MATLAB

После выполнения задания по 1-2 неделям я поигрался с MATLAB для лучшего
понимания материала. Результаты работы скрипта можно посмотреть
[здесь][linear_regression_matlab].


## Week 3

### Логистическая регрессия

Применяется в classification problems (классификация фактов к одному из двух
классов). Примеры - пометка почты как спам, определение злокачественности
опухоли. Для начала рассмотрим бинарную классификацию, а потом расширим на
multiclass classification.

В бинарной классификации значения результата \\( y \in (0,1) \\). Линейная
регрессия в данном случае не очень подходит, т.к. есть сильная зависимость от
значений в training set и значение функции может быть гораздо больше 1.

Удобно использовать в качестве гипотезы логистическую регрессию:

<div>
{% raw %}
\[ h_{\theta}(x) = g(\Theta^T x) \]
\[ g(z) = \frac{1}{1-e^{-z}} \]
{% endraw %}
</div>

В этом случае \\( 0 <= h\_{\theta}(x) <= 1 \\), и мы можем рассматривать значение
функции \\( h \\) в качестве вероятности положительного результата. Если \\(
h\_{\theta}(x) >= 0.5 \\), то \\( y = 1 \\), иначе \\( y = 0 \\).

![sigmoid function]({{ site.url }}/assets/ml/sigmoid.png)

Видно, что \\( y = 1 \\) когда \\( h\_{\theta}(x) >= 0.5, g(z) >= 0.5 \\), т.е.
когда \\( \Theta^T x > 0 \\). Граница \\( \Theta^T x = 0 \\) является decision
boundary. По одну сторону от этой границы располагаются разные классы решения.

Граница решения это свойство не training set но функции гипотезы - \\(
h\_{\theta}(x) \\). В общем случае граница не обязательно прямая (с линейными
членами \\( x^{(i)} \\), можно добавить различные квадратичные члены в
hypothesis function, например чтобы получить границу в виде окружности:

<div>
{% raw %}
\[ h_{\theta}(x) = g(\theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 +\theta_4 x_2^2) \]
{% endraw %}
</div>

Если выбрать

<div>
{% raw %}
\[ \Theta =
    \begin{bmatrix}
    -1\\
    0\\
    0\\
    1\\
    1
    \end{bmatrix}
 \]
{% endraw %}
</div>

то границей будет окружность \\( x\_1^2+x\_2^2 = 1 \\).

[1]: https://www.coursera.org/course/ml
[linear_regression_matlab]: /pages/ml/linear_regression/regression.html
